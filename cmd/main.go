package main

import (
	"consumerwebapp/db"
	"context"
	"fmt"
	"log"
	"time"

	loadCVE "consumerwebapp/services/consumerwebapp"

	"net/http"

	"consumerwebapp/config"

	_ "github.com/lib/pq"
	kafka "github.com/segmentio/kafka-go"
	"github.com/segmentio/kafka-go/sasl"
	"github.com/segmentio/kafka-go/sasl/scram"
)

func checkKafkaConnectivity(brokers []string, mechanism sasl.Mechanism) bool {
	dialer := &kafka.Dialer{
		Timeout:       10 * time.Second,
		DualStack:     true,
		SASLMechanism: mechanism,
	}

	conn, err := dialer.DialContext(context.Background(), "tcp", brokers[0])
	if err != nil {
		log.Printf("Failed to dial Kafka: %v", err)
		return false
	}
	defer conn.Close()

	_, err = conn.Brokers()
	if err != nil {
		log.Printf("Failed to fetch brokers: %v", err)
		return false
	}

	// Check if the 'cve' topic exists
	partitions, err := conn.ReadPartitions("cve")
	if err != nil || len(partitions) == 0 {
		log.Printf("Failed to fetch partitions for topic 'cve': %v", err)
		return false
	}

	return true
}

func healthCheck(mechanism sasl.Mechanism) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		postgresConn, err := db.GetPostgresConn()
		if err != nil {
			http.Error(w, "Database Connection Failed", http.StatusInternalServerError)
			return
		}
		defer postgresConn.Close()

		brokers := []string{
			config.Envs.KafkaBroker0,
			config.Envs.KafkaBroker1,
			config.Envs.KafkaBroker2,
		}
		if !checkKafkaConnectivity(brokers, mechanism) {
			http.Error(w, "Kafka Connection Failed", http.StatusServiceUnavailable)
			return
		}

		fmt.Fprintln(w, "OK", http.StatusOK)
	}
}

func startHTTPServer(mechanism sasl.Mechanism) {
	http.HandleFunc("/healthz", healthCheck(mechanism))
	http.HandleFunc("/livez", livelinessCheck)
	if err := http.ListenAndServe(":8080", nil); err != nil {
		log.Fatal("Failed to start HTTP server: ", err)
	}
}
func livelinessCheck(w http.ResponseWriter, r *http.Request) {
	w.WriteHeader(http.StatusOK)
	fmt.Fprintln(w, "OK", http.StatusOK)
}

func main() {

	postgresConn, err := db.GetPostgresConn()
	if err != nil {
		panic(err)
	} else {
		fmt.Println("Connected to postgres")
	}
	fmt.Println(postgresConn)

	mechanism, err := scram.Mechanism(scram.SHA256, config.Envs.KafkaUser, config.Envs.KafkaPassword)
	if err != nil {
		panic(err)
	}

	go startHTTPServer(mechanism)

	reader := kafka.NewReader(kafka.ReaderConfig{
		Brokers: []string{config.Envs.KafkaBroker0, config.Envs.KafkaBroker1, config.Envs.KafkaBroker2},
		GroupID: "consumer-webapp",
		Topic:   "cve",
		Dialer: &kafka.Dialer{
			Timeout:       10 * time.Second,
			DualStack:     true,
			SASLMechanism: mechanism,
		},
	})

	defer reader.Close()

	cveLoader := loadCVE.NewLoadCVE(postgresConn, reader)

	fmt.Println("start consuming ... !!")

	//Process the messages in event in kafka topic
	for {
		msg, err := reader.ReadMessage(context.Background())
		if err != nil {
			log.Fatal(err)
		}
		//fmt.Printf("Message at offset %d: %s = %s\n", msg.Offset, string(msg.Key), string(msg.Value))

		// Insert message into PostgreSQL database
		_, err = cveLoader.InsertDB(msg.Value)
		if err != nil {
			log.Printf("Failed to insert data: %v", err)
			continue
		}

	}

}
